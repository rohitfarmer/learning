{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(df):\n",
    "    df.drop(labels=[\"Name\", \"Ticket\"], axis=1, inplace=True)\n",
    "    df.Sex.replace(to_replace=[\"male\",\"female\"], value=[1,0], inplace=True)\n",
    "\n",
    "    # Convert categorical Embarked values into one hot encoding.\n",
    "    df = df.join(pd.get_dummies(df.Embarked))\n",
    "    df.drop(labels=\"Embarked\", axis=1, inplace=True)\n",
    "\n",
    "    # Replace NaNs in Age with mean.\n",
    "    df.Age.replace(to_replace=np.nan, value=round(df.Age.mean()), inplace=True)\n",
    "\n",
    "    # Replace NaNs in Fare with mean.\n",
    "    df.Fare.replace(to_replace=np.nan, value=round(df.Fare.mean()), inplace=True)\n",
    "\n",
    "    # Replace NaNs in Cabin with 0 and with 1 for anything else.\n",
    "    df.Cabin.replace(to_replace=np.nan, value=0,inplace=True)\n",
    "    df.loc[df['Cabin'] != 0] = 1\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X and y.\n",
    "# Read data\n",
    "df_train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "df = format_data(df_train)\n",
    "df_X = df.drop(labels=\"Survived\", axis=1)\n",
    "df_X = df_X.astype('float32') # Float32 data type in all the columns.\n",
    "df_y = pd.DataFrame(data=df.Survived, columns=[\"Survived\"]) # Int64 datatype in all the columns.\n",
    "df_y = df_y.astype('float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Tensorflow graph construction phase.\n",
    "tf.reset_default_graph() # Reset default graph if you want to execute this cell multiple times. \n",
    "\n",
    "n_inputs = df_X.shape[1]\n",
    "n_hidden1 = 10\n",
    "n_hidden2 = 5\n",
    "n_outputs = df_y.shape[1]\n",
    "X = tf.placeholder(tf.float32, shape=(None,n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None), name=\"y\")\n",
    "\n",
    "    \n",
    "# Define network architecture\n",
    "hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu,\n",
    "                          kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "                          name=\"hidden1\")\n",
    "\n",
    "# This is how you can get the weights or any other property saved in the graph variables.\n",
    "with tf.variable_scope(\"hidden1\", reuse=True):\n",
    "    weights1 = tf.get_variable(\"kernel\")\n",
    "\n",
    "hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu,\n",
    "                          kernel_regularizer=tf.contrib.layers.l2_regularizer(weights1), \n",
    "                          name=\"hidden2\")\n",
    "\n",
    "with tf.variable_scope(\"hidden2\", reuse=True):\n",
    "    weights2 = tf.get_variable(\"kernel\")\n",
    "    \n",
    "hidden3 = tf.layers.dense(hidden2, n_hidden2, activation=tf.nn.relu,\n",
    "                          kernel_regularizer=tf.contrib.layers.l2_regularizer(weights2), \n",
    "                          name=\"hidden3\")\n",
    "\n",
    "logits = tf.layers.dense(hidden3, n_outputs, name=\"logits\")\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    learning_rate = 0.01\n",
    "    trainer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    # Define the accuracy\n",
    "    #The default threshold is 0.5, rounded off directly\n",
    "    prediction = tf.round(tf.sigmoid(logits))\n",
    "    #prediction = tf.round(logits)\n",
    "    prediction_no_round = tf.sigmoid(logits)\n",
    "    #prediction_no_round = logits\n",
    "    # Bool into float32 type\n",
    "    correct = tf.cast(tf.equal(prediction, y), dtype=tf.float32)\n",
    "    # Average\n",
    "    accuracy = tf.reduce_mean(correct)\n",
    "    \n",
    "    # Using tf.metrics.accuracy method to calculate accuracy\n",
    "    acc, acc_update = tf.metrics.accuracy(labels=y, predictions=prediction_no_round)\n",
    "    \n",
    "    # Using tf.metrics.auc method to calculate auc\n",
    "    auc = tf.metrics.auc(labels=y,predictions=prediction_no_round)\n",
    "\n",
    "# Assign variable initializer\n",
    "init = tf.global_variables_initializer()\n",
    "init_local = tf.local_variables_initializer()\n",
    "\n",
    "# Assign model saver\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoc 9999 Loss 0.21591 Training and test accuracy 0.91358 0.90299 Test AUC 0.940 AUC SK 0.95332 0.228 0.228\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow execution phase.\n",
    "n_epochs = 10000\n",
    "\n",
    "#writer = tf.summary.FileWriter('./graphs', tf.get_default_graph())\n",
    "with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    init.run()\n",
    "    init_local.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        X_train = df_X\n",
    "        y_train = df_y\n",
    "        t, loss_value = sess.run([trainer, loss], feed_dict={X:X_train, y:y_train})\n",
    "        acc_train = accuracy.eval(feed_dict={X:X_train, y:y_train})\n",
    "        acc_test = accuracy.eval(feed_dict={X:X_test, y:y_test})\n",
    "        acc1_train = acc_update.eval(feed_dict={X:X_train, y:y_train})\n",
    "        acc1_test = acc_update.eval(feed_dict={X:X_test, y:y_test})\n",
    "        auc_compute = sess.run(auc, feed_dict={X:X_test, y:y_test})\n",
    "        sigmoid_output = sess.run(prediction_no_round, feed_dict={X:X_test, y:y_test})\n",
    "        avg_loss = np.mean(loss_value) \n",
    "        auc_skleran = roc_auc_score(list(y_test.Survived), list(sigmoid_output))\n",
    "    print(\"Epoc {0:d} Loss {1:.5f} Training and test accuracy {2:.5f} {3:.5f} Test AUC {4:.3f} AUC SK {5:.5f} {6:.3f} {7:.3f}\"\n",
    "              .format(epoch,avg_loss, acc_train, acc_test, auc_compute[0], auc_skleran, acc1_train, acc1_test))\n",
    "    \n",
    "    save_path = saver.save(sess, \"./titanic.ckpt\")\n",
    "    \n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'eval/Sigmoid_1:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_no_round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13623\n"
     ]
    }
   ],
   "source": [
    "print(\"{0:.5f}\".format(float(sigmoid_output[15])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
